import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter

# === 1. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ===
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
st.write("ğŸ”‘ OpenAI API Key is set." if api_key else "âŒ OpenAI API Key is not set.")
# === 2. Streamlit UI ===
st.title("ğŸ“˜ è‡ªå·±ç ”é‘½ä¼‘æš‡ãƒ¬ãƒãƒ¼ãƒˆ(AIä»˜ã)")

st.markdown(
    """
    ã“ã‚“ã«ã¡ã¯ï¼  
    è‡ªå·±ç ”é‘½ä¼‘æš‡ã‚’ã„ãŸã ãæœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ 
    å‹‰å¼·ã—ãŸç”ŸæˆAIã®æŠ€è¡“ã‚’ä½¿ã£ã¦ã€<br>
    **ç”ŸæˆAIã§â€œè…é‡ã£ã½ãç­”ãˆã‚‹AIâ€**ã‚’ä½œã£ã¦ã¿ãŸã®ã§ã€
    ã‚ˆã‹ã£ãŸã‚‰éŠã‚“ã§ã¿ã¦ãã ã•ã„ â˜•ï¸  

    ---
    ### ğŸ® ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„
    - **è…é‡AIãƒ¢ãƒ¼ãƒ‰**ï¼š  
    ChatGPTã«ã€Œã¡ã‚‡ã£ã¨ãƒ•ãƒ©ãƒ³ã‚¯ã«è©±ã—ã¦ã„ã„ã‚ˆã€ã¨ä¼ãˆã¦ã‚ã‚Šã¾ã™ã€‚  
    è…é‡ã®è‡ªå·±ç ”é‘½å†…å®¹ã‚’äº‹å‰ã«æ•™ãˆã¦ã‚ã‚‹ã®ã§ã€å°‘ã—â€œæœ¬äººã£ã½ã„â€å›ç­”ã‚’ã—ã¾ã™ã€‚  

    - **ChatGPTãƒ¢ãƒ¼ãƒ‰**ï¼š  
    ä¸€èˆ¬çš„ãªAIã¨ã—ã¦ã€ãƒ•ãƒ©ãƒƒãƒˆã«å›ç­”ã—ã¾ã™ã€‚  

    <p style="font-size:1rem; margin-top:1em;">
    â€»å›ç­”å†…å®¹ã¯AIãŒè‡ªå‹•ã§ç”Ÿæˆã—ã¦ã„ã¾ã™ã—ã€æ‰€è©®ç§ã®ã‚¹ã‚­ãƒ«ãªã®ã§ã€å¤šå°‘ã®ãƒã‚°ã¯ã”äº†æ‰¿ã‚’ ğŸ˜„
    </p>
    ---
    """,
    unsafe_allow_html=True
)
mode = st.radio(
    "",["è…é‡AIãŒå›ç­”ã—ã¾ã™", "Chat GPTãŒå›ç­”ã—ã¾ã™"]
)

question = st.text_input("æ°—ã«ãªã‚‹ã“ã¨ã‚’ä½•ã§ã‚‚èã„ã¦ã¿ã¦ãã ã•ã„!(å†…å®¹ã«ã‚ˆã£ã¦ã¯ã¡ã‚‡ã£ã¨ç…§ã‚Œã‚‹ã‹ã‚‚)", placeholder="ä¾‹ï¼šã©ã‚“ãªå‹‰å¼·ã—ã¦ãŸã®ï¼Ÿ/ãã‚Œå½¹ã«ç«‹ã¡ãã†ï¼Ÿ/ãŠæ˜¼ä½•é£Ÿã¹ã¦ãŸï¼Ÿ")

# === 3. RAGãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ===
@st.cache_resource
def load_rag_database(excel_path="answerlist.xlsx"):
    if not os.path.exists(excel_path):
        st.warning("âš ï¸ answerlist.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚")
        return None, None

    df = pd.read_excel(excel_path)
    if "content" not in df.columns:
        st.error("âŒ Excelã« 'content' ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™ã€‚")
        return None, None

    df["full_text"] = df.apply(
        lambda row: f"è³ªå•: {row.get('expected_question', '')}\nå›ç­”: {row['content']}\næ—¥ä»˜: {row.get('date', '')}\nã‚¿ã‚°: {row.get('tags', '')}",
        axis=1
    )

    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)
    texts = []
    meta = []
    for _, row in df.iterrows():
        chunks = splitter.split_text(row["full_text"])
        texts.extend(chunks)
        meta.extend([{
            "id": row["id"],
            "image_path": row.get("image_path", None),
            "date": row.get("date", ""),
            "tags": row.get("tags", "")
        }] * len(chunks))

    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    db = FAISS.from_texts(texts, embeddings, metadatas=meta)
    return db, df


# === 4. å›ç­”é–¢æ•° ===
def get_response(question, mode):
    llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.7, openai_api_key=api_key)

    # --- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ---
    if mode == "Chat GPTãŒå›ç­”ã—ã¾ã™":
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯è³ªå•ã«å¯¾ã—ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«ã€å¤±ç¤¼ã«ãªã‚‰ãªã„ç¯„å›²ã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=question)
        ]
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯è³ªå•ã«å¯¾ã—ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«ã€å¤±ç¤¼ã«ãªã‚‰ãªã„ç¯„å›²ã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=question)
        ]
        response = llm.invoke(messages)  # LangChain 0.3ç³»ã§ã¯ invoke ã‚’ä½¿ç”¨
        # LangChain 0.3ç³»ã§ã¯get_openai_callbackãŒå»ƒæ­¢ã•ã‚ŒãŸãŸã‚ã€æ¦‚ç®—æ–™é‡‘ã‚’è¡¨ç¤º
        estimated_cost = 0.001  # æ¦‚ç®—å€¤
        print(f"æ–™é‡‘($): {estimated_cost}")
        return {"text": response.content, "images": [], "cost": estimated_cost}

    # --- RAGå‚ç…§ãƒ¢ãƒ¼ãƒ‰ ---
    elif mode == "è…é‡AIãŒå›ç­”ã—ã¾ã™":
        db, df = load_rag_database()
        if not db:
            return {"text": "RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ãŠè©¦ã—ãã ã•ã„ã€‚", "images": []}

        retriever = db.as_retriever()
        docs = retriever.invoke(question)  # LangChain 0.3ç³»ã§ã¯ invoke ã‚’ä½¿ç”¨
        context = "\n\n".join([d.page_content for d in docs])

        image_paths = list({d.metadata.get("image_path") for d in docs if d.metadata.get("image_path")})

        messages = [
            SystemMessage(content="ã‚ãªãŸã¯è³ªå•ã«å¯¾ã—ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«ã€å¤±ç¤¼ã«ãªã‚‰ãªã„ç¯„å›²ã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=f"ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã‚’ã‚‚ã¨ã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\nå‚è€ƒæƒ…å ±:\n{context}\n\nè³ªå•:{question}")
        ]
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯è³ªå•ã«å¯¾ã—ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«ã€å¤±ç¤¼ã«ãªã‚‰ãªã„ç¯„å›²ã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=f"ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã‚’ã‚‚ã¨ã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\nå‚è€ƒæƒ…å ±:\n{context}\n\nè³ªå•:{question}")
        ]
        response = llm.invoke(messages)  # LangChain 0.3ç³»ã§ã¯ invoke ã‚’ä½¿ç”¨
        # LangChain 0.3ç³»ã§ã¯get_openai_callbackãŒå»ƒæ­¢ã•ã‚ŒãŸãŸã‚ã€æ¦‚ç®—æ–™é‡‘ã‚’è¡¨ç¤º
        estimated_cost = 0.002  # RAGãƒ¢ãƒ¼ãƒ‰ã¯å°‘ã—é«˜ã‚ã®æ¦‚ç®—å€¤
        print(f"æ–™é‡‘($): {estimated_cost}")
        return {"text": response.content, "images": image_paths, "cost": estimated_cost}


# === 5. å®Ÿè¡Œãƒœã‚¿ãƒ³ ===
if st.button("å®Ÿè¡Œ"):
    if not question:
        st.error("âŒ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("ğŸ’¬ å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            result = get_response(question, mode)
            st.divider()
            st.write("### ğŸ§  å›ç­”:")
            st.write(result["text"])
            st.write(f"ğŸ’¸ ã“ã®å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã®ã«ã‹ã‹ã£ãŸAIåˆ©ç”¨æ–™ ${result['cost']:6f}(é«˜ã„ï¼Ÿå®‰ã„ï¼Ÿ)")

            if result["images"]:
                st.write("### ğŸ–¼ é–¢é€£ç”»åƒ:")
                for img_path in result["images"]:
                    if os.path.exists(img_path):
                        st.image(img_path, width=300, caption=os.path.basename(img_path))
                    else:
                        st.write(f"âš ï¸ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_path}")
