import os
import streamlit as st
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_core.chains import RetrievalQA FAISSã‚’ä½¿ã£ã¦ã„ã‚‹ã‹ã‚‰
from langchain.callbacks import get_openai_callback

# === 1. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿ ===
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# === 2. Streamlit UI ===
st.title("ğŸ“˜ è‡ªå·±ç ”é‘½ä¼‘æš‡ãƒ¬ãƒãƒ¼ãƒˆ(AIä»˜ã)")

st.markdown(
    """
    ã“ã‚“ã«ã¡ã¯ï¼  
    è‡ªå·±ç ”é‘½ä¼‘æš‡ã‚’ã„ãŸã ãæœ¬å½“ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ 
    å‹‰å¼·ã—ãŸç”ŸæˆAIã®æŠ€è¡“ã‚’ä½¿ã£ã¦ã€<br>
    **ç”ŸæˆAIã§â€œè…é‡ã£ã½ãç­”ãˆã‚‹AIâ€**ã‚’ä½œã£ã¦ã¿ãŸã®ã§ã€
    ã‚ˆã‹ã£ãŸã‚‰éŠã‚“ã§ã¿ã¦ãã ã•ã„ â˜•ï¸  

    ---
    ### ğŸ® ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„
    - **è…é‡AIãƒ¢ãƒ¼ãƒ‰**ï¼š  
    ChatGPTã«ã€Œã¡ã‚‡ã£ã¨ãƒ•ãƒ©ãƒ³ã‚¯ã«è©±ã—ã¦ã„ã„ã‚ˆã€ã¨ä¼ãˆã¦ã‚ã‚Šã¾ã™ã€‚  
    è…é‡ã®è‡ªå·±ç ”é‘½å†…å®¹ã‚’äº‹å‰ã«æ•™ãˆã¦ã‚ã‚‹ã®ã§ã€å°‘ã—â€œæœ¬äººã£ã½ã„â€å›ç­”ã‚’ã—ã¾ã™ã€‚  

    - **ChatGPTãƒ¢ãƒ¼ãƒ‰**ï¼š  
    ä¸€èˆ¬çš„ãªAIã¨ã—ã¦ã€ãƒ•ãƒ©ãƒƒãƒˆã«å›ç­”ã—ã¾ã™ã€‚  

    <p style="font-size:1rem; margin-top:1em;">
    â€»å›ç­”å†…å®¹ã¯AIãŒè‡ªå‹•ã§ç”Ÿæˆã—ã¦ã„ã¾ã™ã—ã€æ‰€è©®ç§ã®ã‚¹ã‚­ãƒ«ãªã®ã§ã€å¤šå°‘ã®ãƒã‚°ã¯ã”äº†æ‰¿ã‚’ ğŸ˜„
    </p>
    ---
    """,
    unsafe_allow_html=True
)
mode = st.radio(
    "",["è…é‡AIãŒå›ç­”ã—ã¾ã™", "Chat GPTãŒå›ç­”ã—ã¾ã™"]
)

# Example questionsã‚’captionã§è–„ã„è‰²ã§è¡¨ç¤º
# st.caption("ä¾‹ï¼šä½•ã—ã¦ãŸã®ï¼Ÿ/æ¥½ã—ã‹ã£ãŸï¼Ÿ/ãŠæ˜¼ä½•é£Ÿã¹ã¦ãŸï¼Ÿ")

question = st.text_input("æ°—ã«ãªã‚‹ã“ã¨ã‚’ä½•ã§ã‚‚èã„ã¦ã¿ã¦ãã ã•ã„!(å†…å®¹ã«ã‚ˆã£ã¦ã¯ã¡ã‚‡ã£ã¨ç…§ã‚Œã‚‹ã‹ã‚‚)", placeholder="ä¾‹ï¼šã©ã‚“ãªå‹‰å¼·ã—ã¦ãŸã®ï¼Ÿ/ãã‚Œå½¹ã«ç«‹ã¡ãã†ï¼Ÿ/ãŠæ˜¼ä½•é£Ÿã¹ã¦ãŸï¼Ÿ")

# === 3. RAGãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ===
@st.cache_resource
def load_rag_database(excel_path="answerlist.xlsx"):
    if not os.path.exists(excel_path):
        st.warning("âš ï¸ answerlist.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚")
        return None, None

    df = pd.read_excel(excel_path)
    if "content" not in df.columns:
        st.error("âŒ Excelã« 'content' ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™ã€‚")
        return None, None

    # expected_question ã¨ content ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    df["full_text"] = df.apply(
        lambda row: f"è³ªå•: {row.get('expected_question', '')}\nå›ç­”: {row['content']}\næ—¥ä»˜: {row.get('date', '')}\nã‚¿ã‚°: {row.get('tags', '')}",
        axis=1
    )

    splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)
    texts = []
    meta = []
    for _, row in df.iterrows():
        chunks = splitter.split_text(row["full_text"])
        texts.extend(chunks)
        meta.extend([{
            "id": row["id"],
            "image_path": row.get("image_path", None),
            "date": row.get("date", ""),
            "tags": row.get("tags", "")
        }] * len(chunks))

    embeddings = OpenAIEmbeddings(openai_api_key=api_key)
    db = FAISS.from_texts(texts, embeddings, metadatas=meta)
    return db, df


# === æ–™é‡‘è¨ˆç®—ç”¨ ===
# GPT-4o-mini ã®æ–™é‡‘ä¾‹ï¼ˆ$0.0015 / 1K ãƒˆãƒ¼ã‚¯ãƒ³ä»®ï¼‰
PRICE_PER_1K_TOKENS = 0.0015

# === 4. å›ç­”é–¢æ•° ===
def get_response(question, mode):
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7, openai_api_key=api_key)

    # --- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ ---
    if mode == "Chat GPTãŒå›ç­”ã—ã¾ã™":
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯è³ªå•ã«å¯¾ã—ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«ã€å¤±ç¤¼ã«ãªã‚‰ãªã„ç¯„å›²ã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=question)
        ]
        with get_openai_callback() as cb:
            response = llm.predict_messages(messages)
            total_tokens = cb.total_tokens
            total_cost = total_tokens / 1000 * PRICE_PER_1K_TOKENS
            print(f"æ–™é‡‘($): {total_cost}")
            return {"text": response.content, "images": [], "cost": total_cost}

    # --- RAGå‚ç…§ãƒ¢ãƒ¼ãƒ‰ ---
    elif mode == "è…é‡AIãŒå›ç­”ã—ã¾ã™":
        db, df = load_rag_database()
        if not db:
            return {"text": "RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ãŠè©¦ã—ãã ã•ã„ã€‚", "images": []}

        retriever = db.as_retriever()
        docs = retriever.invoke(question)
        context = "\n\n".join([d.page_content for d in docs])

        # ç”»åƒãƒ‘ã‚¹ã‚’æŠ½å‡ºï¼ˆé‡è¤‡ã‚’å‰Šé™¤ï¼‰
        image_paths = list({d.metadata.get("image_path") for d in docs if d.metadata.get("image_path")})

        messages = [
            SystemMessage(content="ã‚ãªãŸã¯è³ªå•ã«å¯¾ã—ã¦ãƒ•ãƒ©ãƒ³ã‚¯ã«ã€å¤±ç¤¼ã«ãªã‚‰ãªã„ç¯„å›²ã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=f"ä»¥ä¸‹ã®å‚è€ƒæƒ…å ±ã‚’ã‚‚ã¨ã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\nå‚è€ƒæƒ…å ±:\n{context}\n\nè³ªå•:{question}")
        ]
        with get_openai_callback() as cb:
            response = llm.predict_messages(messages)
            #print(dir(cb))
            #print(cb.__dict__)
            total_tokens = cb.total_tokens
            total_cost = total_tokens / 1000 * PRICE_PER_1K_TOKENS

            print(f"æ–™é‡‘($): {total_cost}")
            return {"text": response.content, "images": image_paths, "cost": total_cost}


# === 5. å®Ÿè¡Œãƒœã‚¿ãƒ³ ===
if st.button("å®Ÿè¡Œ"):
    if not question:
        st.error("âŒ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("ğŸ’¬ å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            result = get_response(question, mode)
            st.divider()
            st.write("### ğŸ§  å›ç­”:")
            st.write(result["text"])
            st.write(f"ğŸ’¸ ã“ã®å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã®ã«ã‹ã‹ã£ãŸAIåˆ©ç”¨æ–™ ${result['cost']:6f}(é«˜ã„ï¼Ÿå®‰ã„ï¼Ÿ)")

            # ç”»åƒã‚’è¡¨ç¤ºï¼ˆã‚‚ã—RAGãƒ¢ãƒ¼ãƒ‰ã§ã‚ã‚Œã°ï¼‰
            if result["images"]:
                st.write("### ğŸ–¼ é–¢é€£ç”»åƒ:")
                for img_path in result["images"]:
                    if os.path.exists(img_path):
                        st.image(img_path, width=300, caption=os.path.basename(img_path))
                    else:
                        st.write(f"âš ï¸ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_path}")
